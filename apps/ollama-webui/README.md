# Open WebUI

**Open WebUI** 是针对 LLM 用户友好的 WebUI，支持的 LLM 运行程序包括 Ollama、OpenAI 兼容的 API。

## 主要功能：

- **直观的界面**：我们的聊天界面从 ChatGPT 中汲取灵感，确保用户友好的体验。
- **响应式设计**：在桌面和移动设备上享受无缝体验。
- **快速响应**：享受快速响应的性能。
- **轻松部署**：使用 Docker 或 Kubernetes（kubectl、kustomize 或 helm）无缝安装，以获得无忧体验。
- **代码语法高亮**：通过我们的语法突出显示功能增强代码的可读性。
- **Markdown 和 LaTeX 支持**：通过全面的 Markdown 和 LaTeX 功能来丰富交互，提升您的 LLM 体验。
- **RAG 集成**：通过突破性的检索增强生成 (RAG) 支持深入了解聊天交互的未来。此功能将文档交互无缝集成到您的聊天体验中。您可以将文档直接加载到聊天中或将文件添加到文档库中，使用#提示中的命令轻松访问它们。在 alpha 阶段，当我们积极完善和增强此功能以确保最佳性能和可靠性时，可能会偶尔出现问题。
- **网页浏览功能**：使用 `#URL` 后的命令将网站无缝集成到您的聊天体验中。此功能允许您将网络内容直接合并到您的对话中，从而增强交互的丰富性和深度。
- **提示预设支持**：使用聊天输入中的命令立即访问预设提示。轻松加载预定义的对话开头并加快您的互动。通过Open WebUI Community集成轻松导入提示。
- **RLHF 注释**：通过对消息进行“赞成”和“反对”评级来增强您的消息的能力，从而促进根据人类反馈 (RLHF) 创建强化学习数据集。利用您的消息来训练或微调模型，同时确保本地保存数据的机密性。
- **对话管理**：轻松分类和定位特定聊天，以便快速参考和简化数据收集。
- **下载/删除模型**：直接从 Web UI 轻松下载或删除模型。
- **GGUF 文件模型创建**：通过直接从 Web UI 上传 GGUF 文件，轻松创建 Ollama 模型。简化的流程，可选择从您的计算机上传或从 Hugging Face 下载 GGUF 文件。
- **多模型支持**：不同聊天模型之间无缝切换，实现多样化交互。
- **多模式支持**：与支持多模式交互的模型无缝交互，包括图像（例如 LLava）。
- **模型文件生成器**：通过 Web UI 轻松创建 Ollama 模型文件。通过开放 WebUI 社区集成轻松创建和添加角色/代理、自定义聊天元素以及导入模型文件。
- **多个模特对话**：轻松地同时与多个模特互动，利用他们的独特优势来获得最佳响应。通过并行利用一组不同的模型来增强您的体验。
- **协作聊天**：通过无缝编排群组对话来利用多个模型的集体智慧。使用@命令指定模型，在聊天界面中启用动态且多样化的对话。让自己沉浸在聊天环境中的集体智慧中。
- **再生历史访问**：轻松重新访问和探索您的整个再生历史。
- **聊天历史记录**：轻松访问和管理您的对话历史记录。
- **导入/导出聊天历史记录**：将您的聊天数据无缝移入和移出平台。
- **语音输入支持**：通过语音交互与您的模型互动；享受直接与模特交谈的便利。此外，探索在 3 秒静音后自动发送语音输入的选项，以获得简化的体验。
- **使用高级参数进行微调控制**：通过调整温度等参数和定义系统提示来获得更深层次的控制，以根据您的特定偏好和需求定制对话。
- **图像生成集成**：使用 AUTOMATIC1111 API（本地）和 DALL-E 无缝集成图像生成功能，通过动态视觉内容丰富您的聊天体验。
- **OpenAI API 集成**：轻松集成 OpenAI 兼容 API，与 Ollama 模型进行多功能对话。自定义 API 基本 URL 以链接到LMStudio、Mistral、OpenRouter 等。
- **多种 OpenAI 兼容 API 支持**：无缝集成和定制各种 OpenAI 兼容 API，增强聊天交互的多功能性。
- **外部 Ollama 服务器连接**：通过配置环境变量无缝链接到托管在不同地址上的外部 Ollama 服务器。
- **多个 Ollama 实例负载平衡**：轻松地在多个 Ollama 实例之间分配聊天请求，以增强性能和可靠性。
- **多用户管理**：通过我们直观的管理面板轻松监督和管理用户，简化用户管理流程。
- **基于角色的访问控制（RBAC）**：通过受限的权限确保安全访问；只有经过授权的个人才能访问您的 Ollama，并且为管理员保留专有的模型创建/拉取权限。
- **后端反向代理支持**：通过 Open WebUI 后端和 Ollama 之间的直接通信增强安全性。这一关键功能消除了通过 LAN 公开 Ollama 的需要。从 Web UI 向`/ollama/api`路由发出的请求会从后端无缝重定向到 Ollama，从而增强整体系统安全性。
- **持续更新**：我们致力于通过定期更新和新功能来改进 Open WebUI。

**Open WebUI** 提供了广泛的功能集和高度的可扩展性，是理想的 LLM 用户工具。